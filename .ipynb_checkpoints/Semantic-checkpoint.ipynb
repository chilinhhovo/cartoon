{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab11bee-84a6-486e-bf11-79e80feb9d46",
   "metadata": {},
   "source": [
    "## Computer Embeddings to find similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1256d1d-4082-4a5d-8abe-32d153f7e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f5ff83d-b49f-4b77-abb0-b15ec7af9ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fixed version saved: semantic_similarity_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# Load long-format dataset\n",
    "df = pd.read_csv(\"captions_long_format.csv\")\n",
    "\n",
    "# Load HuggingFace sentence embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute embeddings\n",
    "df[\"embedding\"] = df[\"caption\"].astype(str).apply(lambda x: model.encode(x))\n",
    "\n",
    "# STEP 1: Get one top human caption per contest\n",
    "top_humans = (\n",
    "    df[df[\"model\"] == \"Human\"]\n",
    "    .groupby(\"contest\")\n",
    "    .first()\n",
    "    .reset_index()[[\"contest\", \"caption\", \"embedding\"]]\n",
    "    .rename(columns={\"caption\": \"human_caption\", \"embedding\": \"human_embedding\"})\n",
    ")\n",
    "\n",
    "# STEP 2: Drop duplicate AI captions per contest/model/caption\n",
    "ai_df = (\n",
    "    df[df[\"model\"] != \"Human\"]\n",
    "    .drop_duplicates(subset=[\"contest\", \"caption\", \"model\"])\n",
    "    .rename(columns={\"caption\": \"ai_caption\", \"embedding\": \"ai_embedding\"})\n",
    ")\n",
    "\n",
    "# STEP 3: Compute cosine similarity between AI and top human caption\n",
    "results = []\n",
    "\n",
    "for _, ai_row in ai_df.iterrows():\n",
    "    contest_id = ai_row[\"contest\"]\n",
    "    ai_caption = ai_row[\"ai_caption\"]\n",
    "    ai_model = ai_row[\"model\"]\n",
    "    ai_emb = ai_row[\"ai_embedding\"]\n",
    "\n",
    "    human_row = top_humans[top_humans[\"contest\"] == contest_id]\n",
    "    if human_row.empty:\n",
    "        continue\n",
    "\n",
    "    human_caption = human_row[\"human_caption\"].values[0]\n",
    "    human_emb = human_row[\"human_embedding\"].values[0]\n",
    "\n",
    "    similarity = cosine_similarity([ai_emb], [human_emb])[0][0]\n",
    "\n",
    "    results.append({\n",
    "        \"contest\": contest_id,\n",
    "        \"ai_model\": ai_model,\n",
    "        \"ai_caption\": ai_caption,\n",
    "        \"human_caption\": human_caption,\n",
    "        \"semantic_similarity\": similarity\n",
    "    })\n",
    "\n",
    "# Export results\n",
    "sim_df = pd.DataFrame(results)\n",
    "sim_df.to_csv(\"semantic_similarity_cleaned.csv\", index=False)\n",
    "print(\"✅ Fixed version saved: semantic_similarity_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a7ea1e3-599e-4f0f-ba64-66dc6eae42d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence-transformers\n",
    "#!pip install pandas scikit-learn sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f2a7318-d226-48dd-8020-dadc312850a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to semantic_similarity_detailed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"combined_captions_detailed.csv\")\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Rename columns for merging\n",
    "human_df = df[[\"contest\", \"caption_human\"]].rename(columns={\"caption_human\": \"caption\"})\n",
    "human_df[\"model\"] = \"Human\"\n",
    "\n",
    "ai_chatgpt = df[[\"contest\", \"caption_chatgpt\", \"model_chatgpt\"]].rename(\n",
    "    columns={\"caption_chatgpt\": \"caption\", \"model_chatgpt\": \"model\"}\n",
    ")\n",
    "ai_claude = df[[\"contest\", \"caption_claude\", \"model_claude\"]].rename(\n",
    "    columns={\"caption_claude\": \"caption\", \"model_claude\": \"model\"}\n",
    ")\n",
    "\n",
    "# Combine into one long df\n",
    "long_df = pd.concat([human_df, ai_chatgpt, ai_claude], ignore_index=True)\n",
    "long_df = long_df.dropna(subset=[\"caption\"])  # Drop missing\n",
    "long_df[\"caption\"] = long_df[\"caption\"].astype(str)\n",
    "\n",
    "# Separate\n",
    "human_captions = long_df[long_df[\"model\"] == \"Human\"]\n",
    "ai_captions = long_df[long_df[\"model\"] != \"Human\"]\n",
    "\n",
    "results = []\n",
    "\n",
    "for contest_id in ai_captions[\"contest\"].unique():\n",
    "    ai_group = ai_captions[ai_captions[\"contest\"] == contest_id]\n",
    "    human_group = human_captions[human_captions[\"contest\"] == contest_id]\n",
    "\n",
    "    if ai_group.empty or human_group.empty:\n",
    "        continue\n",
    "\n",
    "    # Pre-encode human captions\n",
    "    human_texts = human_group[\"caption\"].tolist()\n",
    "    human_embeddings = model.encode(human_texts)\n",
    "\n",
    "    for _, ai_row in ai_group.iterrows():\n",
    "        ai_caption = ai_row[\"caption\"]\n",
    "        ai_model = ai_row[\"model\"]\n",
    "        ai_embedding = model.encode([ai_caption])[0]\n",
    "\n",
    "        similarities = cosine_similarity([ai_embedding], human_embeddings)[0]\n",
    "\n",
    "        # One row per human caption\n",
    "        for human_caption, sim in zip(human_texts, similarities):\n",
    "            results.append({\n",
    "                \"contest\": contest_id,\n",
    "                \"ai_model\": ai_model,\n",
    "                \"ai_caption\": ai_caption,\n",
    "                \"human_caption\": human_caption,\n",
    "                \"semantic_similarity\": sim\n",
    "            })\n",
    "\n",
    "# Save\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"semantic_similarity_detailed.csv\", index=False)\n",
    "print(\"✅ Saved to semantic_similarity_detailed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6131cdde-f656-4be7-a600-16d90ace075a",
   "metadata": {},
   "source": [
    "## Remove duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3642cacc-fc41-481e-b391-d17322ae7eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'semantic_similarity_deduplicated.csv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the detailed semantic similarity results\n",
    "df = pd.read_csv(\"semantic_similarity_detailed.csv\")\n",
    "\n",
    "# Drop duplicate rows\n",
    "df_deduplicated = df.drop_duplicates()\n",
    "\n",
    "# Save to new file\n",
    "output_path = \"semantic_similarity_deduplicated.csv\"\n",
    "df_deduplicated.to_csv(output_path, index=False)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda074b5-a5db-49f0-978b-5f62f26feb24",
   "metadata": {},
   "source": [
    "## Matching unfunny or funny category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2791024-95a8-48b4-8b18-2a99062e99ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'semantic_similarity_with_matched_category.csv'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the previous semantic similarity results that contain the matched human captions\n",
    "semantic_df = pd.read_csv(\"semantic_similarity_deduplicated.csv\")\n",
    "captions_df = pd.read_csv(\"captions_long_format.csv\")\n",
    "\n",
    "# Ensure text columns are clean\n",
    "semantic_df[\"human_caption\"] = semantic_df[\"human_caption\"].astype(str).str.strip()\n",
    "captions_df[\"caption\"] = captions_df[\"caption\"].astype(str).str.strip()\n",
    "\n",
    "# Only keep human captions with non-null category\n",
    "human_captions_with_cat = captions_df[\n",
    "    (captions_df[\"model\"] == \"Human\") & (captions_df[\"category\"].notna())\n",
    "][[\"contest\", \"caption\", \"category\"]].drop_duplicates()\n",
    "\n",
    "# Merge on both contest + caption to get category from the human reference\n",
    "merged = semantic_df.merge(\n",
    "    human_captions_with_cat,\n",
    "    left_on=[\"contest\", \"human_caption\"],\n",
    "    right_on=[\"contest\", \"caption\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Drop the duplicate 'caption' column from merge\n",
    "merged.drop(columns=[\"caption\"], inplace=True)\n",
    "\n",
    "# Save the updated file\n",
    "final_path = \"semantic_similarity_with_matched_category.csv\"\n",
    "merged.to_csv(final_path, index=False)\n",
    "\n",
    "final_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36609df4-0eb9-4ea8-96f7-5f334c6a50e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
