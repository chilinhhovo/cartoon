{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962b7130-b275-43dd-af09-7b2b03d517c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 vLLM server is launching...\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# Function to launch vllm in background\n",
    "def launch_vllm_server():\n",
    "    command = [\n",
    "        \"vllm\",\n",
    "        \"serve\",\n",
    "        \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "        \"--trust-remote-code\",\n",
    "        \"--port\", \"8000\",\n",
    "        \"--dtype\", \"half\",\n",
    "        \"--max-model-len\", \"16384\",\n",
    "        \"--enable-chunked-prefill\", \"true\"\n",
    "    ]\n",
    "\n",
    "    def run():\n",
    "        subprocess.run(command)\n",
    "\n",
    "    thread = threading.Thread(target=run, daemon=True)\n",
    "    thread.start()\n",
    "    print(\"🚀 vLLM server is launching...\")\n",
    "\n",
    "# Call this once in the notebook\n",
    "launch_vllm_server()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2fe5ca7-227c-4997-849e-7d0b736f4d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (0.115.11)\n",
      "Requirement already satisfied: nest-asyncio in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: pyngrok in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (7.2.3)\n",
      "Requirement already satisfied: uvicorn in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (0.34.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from fastapi) (0.46.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from fastapi) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from fastapi) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pyngrok) (6.0.2)\n",
      "Requirement already satisfied: click>=7.0 in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.8.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (2.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi nest-asyncio pyngrok uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae3693b-c755-413c-9d0a-c2d4f05865d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-22 05:32:21 [__init__.py:256] Automatically detected platform cpu.\n",
      "INFO 03-22 05:32:21 [api_server.py:977] vLLM API server version 0.8.1\n",
      "INFO 03-22 05:32:21 [api_server.py:978] args: Namespace(subparser='serve', model_tag='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='auto', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, enable_ssl_refresh=False, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', task='auto', tokenizer=None, hf_config_path=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=True, allowed_local_media_path=None, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='half', kv_cache_dtype='auto', max_model_len=16384, guided_decoding_backend='xgrammar', logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=1, enable_expert_parallel=False, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=None, enable_prefix_caching=None, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=None, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_partial_prefills=1, max_long_partial_prefills=1, long_prefill_token_threshold=0, max_num_seqs=None, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, disable_mm_preprocessor_cache=False, enable_lora=False, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, use_tqdm_on_load=True, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=True, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', scheduler_cls='vllm.core.scheduler.Scheduler', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=None, worker_cls='auto', worker_extension_cls='', generation_config='auto', override_generation_config=None, enable_sleep_mode=False, calculate_kv_scales=False, additional_config=None, enable_reasoning=False, reasoning_parser=None, disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False, enable_server_load_tracking=False, dispatch_function=<function ServeSubcommand.cmd at 0x2f2866b00>)\n",
      "WARNING 03-22 05:32:21 [config.py:2599] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 03-22 05:32:27 [config.py:583] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.\n",
      "WARNING 03-22 05:32:27 [arg_utils.py:1765] device type=cpu is not supported by the V1 Engine. Falling back to V0. \n",
      "INFO 03-22 05:32:27 [config.py:1693] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
      "WARNING 03-22 05:32:27 [cpu.py:94] Environment variable VLLM_CPU_KVCACHE_SPACE (GB) for CPU backend is not set, using 4 by default.\n",
      "WARNING 03-22 05:32:27 [cpu.py:107] uni is not supported on CPU, fallback to mp distributed executor backend.\n",
      "INFO 03-22 05:32:27 [api_server.py:241] Started engine process with PID 54003\n",
      "INFO 03-22 05:32:32 [__init__.py:256] Automatically detected platform cpu.\n",
      "INFO 03-22 05:32:32 [llm_engine.py:241] Initializing a V0 LLM engine (v0.8.1) with config: model='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=16384, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cpu, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=True, \n",
      "INFO 03-22 05:32:33 [cpu.py:40] Using Torch SDPA backend.\n",
      "WARNING 03-22 05:32:33 [_custom_ops.py:21] Failed to import from vllm._C with ImportError('dlopen(/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/_C.abi3.so, 0x0002): Symbol not found: __ZNK3c1011StorageImpl27throw_data_ptr_access_errorEv\\n  Referenced from: <342AB6BC-6ACE-32DC-AD0A-D95B392DE44E> /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/_C.abi3.so\\n  Expected in:     <BA9C42A5-EA1D-3784-80E1-73FBFDE05847> /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/lib/libc10.dylib')\n",
      "INFO 03-22 05:32:33 [importing.py:16] Triton not installed or not compatible; certain GPU-related functions will not be available.\n",
      "INFO 03-22 05:32:33 [parallel_state.py:967] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "ERROR 03-22 05:32:33 [engine.py:448] '_OpNamespace' '_C' object has no attribute 'silu_and_mul'\n",
      "ERROR 03-22 05:32:33 [engine.py:448] Traceback (most recent call last):\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/engine/multiprocessing/engine.py\", line 436, in run_mp_engine\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     engine = MQLLMEngine.from_vllm_config(\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/engine/multiprocessing/engine.py\", line 128, in from_vllm_config\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     return cls(\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/engine/multiprocessing/engine.py\", line 82, in __init__\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     self.engine = LLMEngine(*args, **kwargs)\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 280, in __init__\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     self.model_executor = executor_class(vllm_config=vllm_config, )\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/executor/executor_base.py\", line 271, in __init__\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     super().__init__(*args, **kwargs)\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/executor/executor_base.py\", line 52, in __init__\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     self._init_executor()\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/executor/mp_distributed_executor.py\", line 125, in _init_executor\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     self._run_workers(\"load_model\",\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/executor/mp_distributed_executor.py\", line 185, in _run_workers\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     driver_worker_output = run_method(self.driver_worker, sent_method,\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/utils.py\", line 2216, in run_method\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     return func(*args, **kwargs)\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/worker/cpu_worker.py\", line 225, in load_model\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     self.model_runner.load_model()\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/worker/cpu_model_runner.py\", line 490, in load_model\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     self.model = get_model(vllm_config=self.vllm_config)\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py\", line 14, in get_model\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     return loader.load_model(vllm_config=vllm_config)\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py\", line 423, in load_model\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     model = _initialize_model(vllm_config=vllm_config)\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py\", line 126, in _initialize_model\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     return model_class(vllm_config=vllm_config, prefix=prefix)\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py\", line 431, in __init__\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     self.model = Qwen2Model(vllm_config=vllm_config,\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/compilation/decorators.py\", line 151, in __init__\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py\", line 300, in __init__\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     self.start_layer, self.end_layer, self.layers = make_layers(\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/models/utils.py\", line 557, in make_layers\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     [PPMissingLayer() for _ in range(start_layer)] + [\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/models/utils.py\", line 558, in <listcomp>\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     maybe_offload_to_cpu(layer_fn(prefix=f\"{prefix}.{idx}\"))\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py\", line 302, in <lambda>\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     lambda prefix: Qwen2DecoderLayer(config=config,\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py\", line 218, in __init__\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     self.mlp = Qwen2MLP(\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py\", line 92, in __init__\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     self.act_fn = SiluAndMul()\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/layers/activation.py\", line 68, in __init__\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     self.op = torch.ops._C.silu_and_mul\n",
      "ERROR 03-22 05:32:33 [engine.py:448]   File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/_ops.py\", line 1225, in __getattr__\n",
      "ERROR 03-22 05:32:33 [engine.py:448]     raise AttributeError(\n",
      "ERROR 03-22 05:32:33 [engine.py:448] AttributeError: '_OpNamespace' '_C' object has no attribute 'silu_and_mul'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/engine/multiprocessing/engine.py\", line 450, in run_mp_engine\n",
      "    raise e\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/engine/multiprocessing/engine.py\", line 436, in run_mp_engine\n",
      "    engine = MQLLMEngine.from_vllm_config(\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/engine/multiprocessing/engine.py\", line 128, in from_vllm_config\n",
      "    return cls(\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/engine/multiprocessing/engine.py\", line 82, in __init__\n",
      "    self.engine = LLMEngine(*args, **kwargs)\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 280, in __init__\n",
      "    self.model_executor = executor_class(vllm_config=vllm_config, )\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/executor/executor_base.py\", line 271, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/executor/executor_base.py\", line 52, in __init__\n",
      "    self._init_executor()\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/executor/mp_distributed_executor.py\", line 125, in _init_executor\n",
      "    self._run_workers(\"load_model\",\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/executor/mp_distributed_executor.py\", line 185, in _run_workers\n",
      "    driver_worker_output = run_method(self.driver_worker, sent_method,\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/utils.py\", line 2216, in run_method\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/worker/cpu_worker.py\", line 225, in load_model\n",
      "    self.model_runner.load_model()\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/worker/cpu_model_runner.py\", line 490, in load_model\n",
      "    self.model = get_model(vllm_config=self.vllm_config)\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py\", line 14, in get_model\n",
      "    return loader.load_model(vllm_config=vllm_config)\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py\", line 423, in load_model\n",
      "    model = _initialize_model(vllm_config=vllm_config)\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py\", line 126, in _initialize_model\n",
      "    return model_class(vllm_config=vllm_config, prefix=prefix)\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py\", line 431, in __init__\n",
      "    self.model = Qwen2Model(vllm_config=vllm_config,\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/compilation/decorators.py\", line 151, in __init__\n",
      "    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py\", line 300, in __init__\n",
      "    self.start_layer, self.end_layer, self.layers = make_layers(\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/models/utils.py\", line 557, in make_layers\n",
      "    [PPMissingLayer() for _ in range(start_layer)] + [\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/models/utils.py\", line 558, in <listcomp>\n",
      "    maybe_offload_to_cpu(layer_fn(prefix=f\"{prefix}.{idx}\"))\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py\", line 302, in <lambda>\n",
      "    lambda prefix: Qwen2DecoderLayer(config=config,\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py\", line 218, in __init__\n",
      "    self.mlp = Qwen2MLP(\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py\", line 92, in __init__\n",
      "    self.act_fn = SiluAndMul()\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/model_executor/layers/activation.py\", line 68, in __init__\n",
      "    self.op = torch.ops._C.silu_and_mul\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/_ops.py\", line 1225, in __getattr__\n",
      "    raise AttributeError(\n",
      "AttributeError: '_OpNamespace' '_C' object has no attribute 'silu_and_mul'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/bin/vllm\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/entrypoints/cli/main.py\", line 75, in main\n",
      "    args.dispatch_function(args)\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/entrypoints/cli/serve.py\", line 33, in cmd\n",
      "    uvloop.run(run_server(args))\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/uvloop/__init__.py\", line 82, in run\n",
      "    return loop.run_until_complete(wrapper())\n",
      "  File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/uvloop/__init__.py\", line 61, in wrapper\n",
      "    return await main\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py\", line 1012, in run_server\n",
      "    async with build_async_engine_client(args) as engine_client:\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/contextlib.py\", line 199, in __aenter__\n",
      "    return await anext(self.gen)\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py\", line 141, in build_async_engine_client\n",
      "    async with build_async_engine_client_from_engine_args(\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/contextlib.py\", line 199, in __aenter__\n",
      "    return await anext(self.gen)\n",
      "  File \"/Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py\", line 264, in build_async_engine_client_from_engine_args\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Engine process failed to start. See stack trace for the root cause.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def ask_model(question, model=\"facebook/opt-350m\"):\n",
    "    url = \"http://localhost:8000/v1/chat/completions\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question}],\n",
    "        \"max_tokens\": 100\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"❌ Error communicating with model:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c5c4c07-47e8-4dd5-b709-f1724e08cf0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b280026f843e403bb0570cf5d5a89750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a sarcastic caption about frogs. I want to use it in a social media post. It should be humorous but not offensive. I need to include the frog's life stages: egg, tadpole, tad, frog. Also, I should mention the frog's lifespan and why frogs\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "inputs = tokenizer(\"Tell me a sarcastic caption about frogs.\", return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "675a9efe-6f4e-4d52-9122-74d531b0eacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a sarcastic caption about frogs. I want to use it in a social media post. It should be humorous but not offensive. I need to include the frog's life stages: egg, tadpole, tad, frog. Also, I should mention the frog's lifespan and why frogs\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "outputs = model.generate(**inputs, max_new_tokens=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4df3b97a-4696-4be9-9fa3-88a59faf02d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: deepseek_vl\n",
      "Version: 1.0.0\n",
      "Summary: DeepSeek-VL\n",
      "Home-page: https://github.com/deepseek-ai/DeepSeek-VL\n",
      "Author: DeepSeek-AI\n",
      "Author-email: \n",
      "License: MIT License\n",
      "        \n",
      "        Copyright (c) 2023 DeepSeek\n",
      "        \n",
      "        Permission is hereby granted, free of charge, to any person obtaining a copy\n",
      "        of this software and associated documentation files (the \"Software\"), to deal\n",
      "        in the Software without restriction, including without limitation the rights\n",
      "        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
      "        copies of the Software, and to permit persons to whom the Software is\n",
      "        furnished to do so, subject to the following conditions:\n",
      "        \n",
      "        The above copyright notice and this permission notice shall be included in all\n",
      "        copies or substantial portions of the Software.\n",
      "        \n",
      "        THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
      "        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
      "        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
      "        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
      "        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
      "        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
      "        SOFTWARE.\n",
      "        \n",
      "Location: /Users/chivo/.pyenv/versions/3.10.12/lib/python3.10/site-packages\n",
      "Editable project location: /Users/chivo/DeepSeek-VL\n",
      "Requires: accelerate, attrdict, einops, sentencepiece, timm, torch, transformers\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show deepseek_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8159099b-32b8-47a4-bf85-67f0d1c9cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/chivo/DeepSeek-VL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d02a67d-4504-4200-9288-6040281bd2f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: mask_prompt, image_tag, add_special_token, ignore_id, sft_format, num_image_tokens. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4cd72734c3449c9693b81f2ff55d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 No existing captions found. Starting fresh.\n",
      "❌ Error processing 807_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 689_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 538_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 634_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 764_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 585_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 623_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 773_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 592_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 810_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 883_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 829_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 516_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 894_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 814_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 777_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 627_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 596_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 760_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 630_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 581_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 803_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 890_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 512_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 887_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 759_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 609_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 860_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 703_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 653_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 714_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 644_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 548_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 877_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 566_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 859_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 787_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 571_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 790_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 873_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 640_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 710_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 657_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 707_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 864_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 679_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 729_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 575_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 794_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 562_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 783_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 874_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 717_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 647_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 700_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 650_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 863_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 572_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 793_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 565_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 784_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 739_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 669_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 558_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 867_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 654_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 704_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 643_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 713_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 870_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 561_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 780_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 576_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 797_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 849_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 813_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 620_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 770_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 591_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 637_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 767_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 586_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 804_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 619_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 749_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 515_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 880_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 800_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 763_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 633_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 582_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 774_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 624_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 595_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 699_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 817_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 528_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 884_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 839_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 511_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 893_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 522_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 693_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 588_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 639_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 769_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 535_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 684_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 617_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 747_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 824_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 833_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 600_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 750_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 531_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 680_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 526_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 697_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 819_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 754_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 604_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 837_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 820_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 743_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 613_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 545_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 719_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 649_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 552_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 720_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 670_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 843_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 854_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 737_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 667_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 869_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 556_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 541_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 663_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 733_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 850_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 799_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 847_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 578_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 674_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 724_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 551_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 879_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 546_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 734_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 664_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 857_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 789_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 568_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 840_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 723_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 673_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 542_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 659_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 709_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 555_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 677_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 727_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 844_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 853_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 660_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 730_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 536_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 809_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 687_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 521_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 690_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 603_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 753_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 830_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 518_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 827_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 614_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 744_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 694_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 598_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 779_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 629_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 532_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 683_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 740_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 610_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 823_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 834_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 889_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 757_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 607_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 661_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 731_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 852_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 845_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 676_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 726_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 554_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 658_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 708_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 543_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 722_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 672_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 841_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 856_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 788_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 569_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 735_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 665_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 878_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 547_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 550_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 888_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 756_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 606_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 835_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 822_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 741_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 611_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 533_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 682_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 599_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 778_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 628_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 524_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 695_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 615_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 745_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 519_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 826_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 831_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 602_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 752_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 520_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 691_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 537_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 808_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 686_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 742_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 612_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 821_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 836_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 755_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 605_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 527_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 696_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 818_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 530_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 681_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 601_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 751_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 832_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 825_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 616_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 746_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 534_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 685_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 589_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 638_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 768_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 523_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 692_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 675_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 725_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 798_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 846_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 579_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 851_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 662_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 732_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 540_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 868_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 557_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 736_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 666_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 855_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 842_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 721_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 671_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 553_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 718_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 648_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 544_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 577_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 796_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 848_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 560_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 781_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 871_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 642_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 712_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 655_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 705_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 559_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 866_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 738_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 668_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 564_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 785_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 573_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 792_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 862_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 701_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 651_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 716_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 646_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 875_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 892_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 510_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 838_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 885_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 698_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 816_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 529_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 775_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 625_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 594_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 762_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 632_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 583_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 801_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 881_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 514_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 618_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 748_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 805_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 636_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 766_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 587_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 621_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 771_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 590_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 812_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 886_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 758_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 608_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 513_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 891_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 802_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 761_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 631_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 580_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 776_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 626_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 597_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 815_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 895_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 828_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 517_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 882_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 811_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 622_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 772_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 593_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 635_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 765_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 584_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 806_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 688_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 539_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 563_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 782_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 574_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 795_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 678_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 728_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 865_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 656_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 706_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 641_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 711_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 872_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 570_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 791_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 567_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 858_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 786_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 549_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 876_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 715_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 645_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 702_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 652_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "❌ Error processing 861_Dashboard: Input type (c10::BFloat16) and bias type (c10::Half) should be the same\n",
      "✅ All captions already exist. Nothing new to save.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from deepseek_vl.models import VLChatProcessor, MultiModalityCausalLM\n",
    "from deepseek_vl.utils.io import load_pil_images\n",
    "\n",
    "# Model path\n",
    "model_path = \"deepseek-ai/deepseek-vl-7b-chat\"\n",
    "\n",
    "# Load model and processor\n",
    "vl_chat_processor: VLChatProcessor = VLChatProcessor.from_pretrained(model_path)\n",
    "tokenizer = vl_chat_processor.tokenizer\n",
    "\n",
    "# Load the model and move to float16 or float32 as needed\n",
    "vl_gpt: MultiModalityCausalLM = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "vl_gpt = vl_gpt.half().to(device).eval()  # or use .float() for float32\n",
    "\n",
    "\n",
    "# Paths\n",
    "image_folder = \"contest_images\"\n",
    "existing_csv_path = \"/Users/chivo/Downloads/data_studio/project4/new_yorker_contest/ai_captions_deepseek.csv\"\n",
    "\n",
    "# Load existing captions\n",
    "if os.path.exists(existing_csv_path):\n",
    "    existing_df = pd.read_csv(existing_csv_path)\n",
    "    already_captioned_ids = set(existing_df[\"contest\"].astype(str))\n",
    "    print(f\"📄 Found existing captions for {len(already_captioned_ids)} contests.\")\n",
    "else:\n",
    "    existing_df = None\n",
    "    already_captioned_ids = set()\n",
    "    print(\"📄 No existing captions found. Starting fresh.\")\n",
    "\n",
    "output = []\n",
    "\n",
    "# Loop through images\n",
    "for image_name in os.listdir(image_folder):\n",
    "    if not image_name.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    contest_id = os.path.splitext(image_name)[0]\n",
    "    if contest_id in already_captioned_ids:\n",
    "        print(f\"⏩ Skipping {contest_id} (already captioned)\")\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    prompt = \"Write a clever one-line caption for a New Yorker-style cartoon.\"\n",
    "\n",
    "    # Set up conversation\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"User\",\n",
    "            \"content\": f\"<image_placeholder>{prompt}\",\n",
    "            \"images\": [image_path]\n",
    "        },\n",
    "        {\"role\": \"Assistant\", \"content\": \"\"}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Load and process image\n",
    "        pil_images = load_pil_images(conversation)\n",
    "        prepare_inputs = vl_chat_processor(\n",
    "            conversations=conversation,\n",
    "            images=pil_images,\n",
    "            force_batchify=True\n",
    "        ).to(device)\n",
    "\n",
    "        inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
    "        inputs_embeds = {\n",
    "            k: v.to(dtype=torch.float16) if isinstance(v, torch.Tensor) else v\n",
    "            for k, v in inputs_embeds.items()\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        # Generate caption\n",
    "        outputs = vl_gpt.language_model.generate(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            attention_mask=prepare_inputs.attention_mask,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            bos_token_id=tokenizer.bos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens=64,\n",
    "            do_sample=True,\n",
    "            temperature=0.9,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.3\n",
    "        )\n",
    "\n",
    "        caption = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True).replace(prompt, \"\").strip()\n",
    "        print(f\"✅ [{contest_id}] Caption: {caption}\")\n",
    "\n",
    "        output.append({\n",
    "            \"contest\": contest_id,\n",
    "            \"model\": \"DeepSeek-VL-7B\",\n",
    "            \"caption\": caption\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {contest_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save to CSV\n",
    "if output:\n",
    "    new_df = pd.DataFrame(output)\n",
    "    if existing_df is not None:\n",
    "        full_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "    else:\n",
    "        full_df = new_df\n",
    "    full_df.to_csv(existing_csv_path, index=False)\n",
    "    print(f\"💾 Saved {len(new_df)} new captions to: {existing_csv_path}\")\n",
    "else:\n",
    "    print(\"✅ All captions already exist. Nothing new to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfcb37cf-a051-49d4-97cb-5b132f183e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contest</th>\n",
       "      <th>model</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>807_Dashboard</td>\n",
       "      <td>DeepSeek (local)</td>\n",
       "      <td>_3_Cover_619.\\n\\nThe original text is as follo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>689_Dashboard</td>\n",
       "      <td>DeepSeek (local)</td>\n",
       "      <td>_1000_Square_Cartoon\\nThe contest is about cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>538_Dashboard</td>\n",
       "      <td>DeepSeek (local)</td>\n",
       "      <td>The image in the previous post is [the graph o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>634_Dashboard</td>\n",
       "      <td>DeepSeek (local)</td>\n",
       "      <td>_2015.\\nThe description says:\\n\"Find the maxim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>764_Dashboard</td>\n",
       "      <td>DeepSeek (local)</td>\n",
       "      <td>_21908_Cartoon. You can use the following word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>715_Dashboard</td>\n",
       "      <td>DeepSeek (local)</td>\n",
       "      <td>.\\nAlright, so I need to write a one-liner tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>645_Dashboard</td>\n",
       "      <td>DeepSeek (local)</td>\n",
       "      <td>_3_Cooning.\\n\\nThe goal is to make the image a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>702_Dashboard</td>\n",
       "      <td>DeepSeek (local)</td>\n",
       "      <td>_Carrot_Wrap.\\nThe contest involves writing an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>652_Dashboard</td>\n",
       "      <td>DeepSeek (local)</td>\n",
       "      <td>(the new dashboard) is being presented in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>861_Dashboard</td>\n",
       "      <td>DeepSeek (local)</td>\n",
       "      <td>, and it's about the transition from an old to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           contest             model  \\\n",
       "0    807_Dashboard  DeepSeek (local)   \n",
       "1    689_Dashboard  DeepSeek (local)   \n",
       "2    538_Dashboard  DeepSeek (local)   \n",
       "3    634_Dashboard  DeepSeek (local)   \n",
       "4    764_Dashboard  DeepSeek (local)   \n",
       "..             ...               ...   \n",
       "380  715_Dashboard  DeepSeek (local)   \n",
       "381  645_Dashboard  DeepSeek (local)   \n",
       "382  702_Dashboard  DeepSeek (local)   \n",
       "383  652_Dashboard  DeepSeek (local)   \n",
       "384  861_Dashboard  DeepSeek (local)   \n",
       "\n",
       "                                               caption  \n",
       "0    _3_Cover_619.\\n\\nThe original text is as follo...  \n",
       "1    _1000_Square_Cartoon\\nThe contest is about cre...  \n",
       "2    The image in the previous post is [the graph o...  \n",
       "3    _2015.\\nThe description says:\\n\"Find the maxim...  \n",
       "4    _21908_Cartoon. You can use the following word...  \n",
       "..                                                 ...  \n",
       "380  .\\nAlright, so I need to write a one-liner tha...  \n",
       "381  _3_Cooning.\\n\\nThe goal is to make the image a...  \n",
       "382  _Carrot_Wrap.\\nThe contest involves writing an...  \n",
       "383  (the new dashboard) is being presented in the ...  \n",
       "384  , and it's about the transition from an old to...  \n",
       "\n",
       "[385 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100fa71f-4bb6-4c48-8353-90735e4058c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📷 Sending image: contest_images/807_Dashboard.jpg, size = 1020.4 KB\n",
      "❌ [807_Dashboard] HTTP Error: 400 Client Error: Bad Request for url: https://api.deepseek.com/v1/chat/completions\n",
      "🔍 DeepSeek response: {\"error\":{\"message\":\"Model Not Exist\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":\"invalid_request_error\"}}\n",
      "\n",
      "📷 Sending image: contest_images/689_Dashboard.jpg, size = 396.6 KB\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m contest_id \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(image_name)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     57\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_folder, image_name)\n\u001b[0;32m---> 59\u001b[0m caption \u001b[38;5;241m=\u001b[39m \u001b[43mcall_deepseek_vision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontest_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m caption:\n\u001b[1;32m     61\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontest\u001b[39m\u001b[38;5;124m\"\u001b[39m: contest_id,\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSeek-VL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m\"\u001b[39m: caption\n\u001b[1;32m     65\u001b[0m     })\n",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m, in \u001b[0;36mcall_deepseek_vision\u001b[0;34m(img_path, contest_id)\u001b[0m\n\u001b[1;32m     27\u001b[0m body \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek-vl\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# ✅ fixed model name\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     37\u001b[0m }\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://api.deepseek.com/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     42\u001b[0m     caption \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "deepseek_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {deepseek_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Folder where your cartoons live\n",
    "image_folder = \"contest_images\"\n",
    "output = []\n",
    "\n",
    "def call_deepseek_vision(img_path, contest_id):\n",
    "    with open(img_path, \"rb\") as img_file:\n",
    "        encoded = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    print(f\"\\n📷 Sending image: {img_path}, size = {os.path.getsize(img_path)/1024:.1f} KB\")\n",
    "\n",
    "    body = {\n",
    "        \"model\": \"deepseek-vl\",  # ✅ fixed model name\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Write a clever, dry, or absurd one-line caption. Think like The New Yorker.\"\n",
    "            }\n",
    "        ],\n",
    "        \"image\": f\"data:image/jpeg;base64,{encoded}\",\n",
    "        \"max_tokens\": 100\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\"https://api.deepseek.com/v1/chat/completions\", headers=headers, json=body)\n",
    "        response.raise_for_status()\n",
    "        caption = response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        print(f\"✅ [{contest_id}] Caption: {caption}\")\n",
    "        return caption\n",
    "\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"❌ [{contest_id}] HTTP Error: {e}\")\n",
    "        print(\"🔍 DeepSeek response:\", response.text)\n",
    "        return None\n",
    "\n",
    "# Caption every image\n",
    "for image_name in os.listdir(image_folder):\n",
    "    if not image_name.lower().endswith(\".jpg\"):\n",
    "        continue\n",
    "\n",
    "    contest_id = os.path.splitext(image_name)[0]\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "\n",
    "    caption = call_deepseek_vision(image_path, contest_id)\n",
    "    if caption:\n",
    "        output.append({\n",
    "            \"contest\": contest_id,\n",
    "            \"model\": \"DeepSeek-VL\",\n",
    "            \"caption\": caption\n",
    "        })\n",
    "\n",
    "    time.sleep(2)  # polite pause to avoid rate limit\n",
    "\n",
    "# Save all captions\n",
    "df = pd.DataFrame(output)\n",
    "csv_path = \"captions_deepseek_vl.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\n💾 Captions saved to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a952d9a-9592-4742-80da-2a023d6df6e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "illegal target for annotation (2923736107.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"model\": \"deepseek-vl-7b\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal target for annotation\n"
     ]
    }
   ],
   "source": [
    "\"model\": \"deepseek-vl-7b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840ee357-b4f8-451e-ac5e-65ed902a5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def ask_model(contest_id, model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"):\n",
    "    url = \"http://localhost:8000/v1/chat/completions\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    # 📜 Prompt template\n",
    "    prompt = (\n",
    "        f\"This is a caption contest cartoon from contest ID {contest_id}. \"\n",
    "        \"Write a witty, clever, absurd, or dry one-line caption as if it were for The New Yorker. \"\n",
    "        \"Do not explain anything. Just output the caption. Keep it under 30 words.\"\n",
    "    )\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": 100,\n",
    "        \"temperature\": 0.9,\n",
    "        \"top_p\": 0.95,\n",
    "        \"repetition_penalty\": 1.2\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ [Error for {contest_id}]:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3c2b54-61fa-4a8d-b0c4-cf016255c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def ask_model(question, model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"):\n",
    "    url = \"http://localhost:8000/v1/chat/completions\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question}],\n",
    "        \"max_tokens\": 100\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"❌ Error communicating with model:\", e)\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "response = ask_model(\"Write a funny cartoon caption about two cats arguing over a pizza.\")\n",
    "print(\"📝 Model response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d4c2b7a-f3c9-40cb-ba44-b411ed1225b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ [Error for 895_Dashboard]: 404 Client Error: Not Found for url: http://localhost:8000/v1/chat/completions\n",
      "📝 Caption for 895_Dashboard:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "caption = ask_model(\"895_Dashboard\")\n",
    "print(f\"📝 Caption for 895_Dashboard:\\n{caption}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6079a3-b467-42ae-866c-2759be385e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
